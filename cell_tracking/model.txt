

def mpnn_in_def_d_own_neighbours_crop_feat_dcrop(node_dim, edge_dim, message_steps, hidden_units):

        node_features = layers.Input((node_dim), dtype="float32", name="node_features")
        edge_features = layers.Input((edge_dim), dtype="float32", name="edge_features")
        edge_indices = layers.Input((2), dtype="int32", name="edge_indices")

        edge_encoder = dnn_block(hidden_units, edge_dim*3)
        n_to_e_NN = dnn_block(hidden_units, edge_dim*3)
        e_to_n_NN = dnn_block(hidden_units, 12)
        edge_classification = dnn_block(hidden_units, hidden_units)


        # node_features = data_set[0][0]

        # Encode the nodes:
        # [16*24,1] --> [16,24] ------> [2,3] --> [2*3,1]
        hi = tf.keras.layers.Reshape((16, 24))(node_features)
        hi = tf.expand_dims(hi,-1)
        hi = tf.keras.layers.Conv2D(128, (3, 3), strides = (1, 1), padding="same", kernel_initializer = tf.keras.initializers.glorot_uniform(seed=0))(hi)
        hi = tf.keras.layers.LeakyReLU()(hi)
        hi = tf.keras.layers.Conv2D(128, (3, 3), strides = (1, 1), padding="same", kernel_initializer = tf.keras.initializers.glorot_uniform(seed=0))(hi)
        hi = tf.keras.layers.LeakyReLU()(hi)
        hi = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2))(hi)

        # hi = hi.numpy()

        hi = tf.keras.layers.Conv2D(64, (3, 3), strides = (1, 1), padding="same", kernel_initializer = tf.keras.initializers.glorot_uniform(seed=0))(hi)
        hi = tf.keras.layers.LeakyReLU()(hi)
        hi = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2))(hi)

        # hi = hi.numpy()

        hi = tf.keras.layers.Conv2D(32, (3, 3), strides = (1, 1), padding="same", kernel_initializer = tf.keras.initializers.glorot_uniform(seed=0))(hi)
        hi = tf.keras.layers.LeakyReLU()(hi)
        hi = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2))(hi)

        hi = tf.keras.layers.Flatten()(hi)


        hi = layers.Dense(12,kernel_initializer=tf.keras.initializers.HeNormal())(hi)
        hi = tf.keras.layers.LeakyReLU()(hi)
        hi = tf.keras.layers.LayerNormalization()(hi)

        # hi = hi.numpy()

        # Encode the edges:
        ai = tf.gather(hi, edge_indices[:, 0])
        aj = tf.gather(hi, edge_indices[:, 1])
        #a = tf.sqrt(tf.square(tf.subtract(ai, aj)))
        a = tf.subtract(ai, aj)
        ea = tf.concat((edge_features, a), 1)
        hij = edge_encoder(ea)

        for step in range(message_steps):
            # Construct the node --> edge matrix: hij' = [hi, hj, hij]
            hi_long = tf.gather(hi, edge_indices[:, 0])
            hj_long = tf.gather(hi, edge_indices[:, 1])
            edge_combi = tf.concat((hi_long, hj_long, hij), 1)
            message = n_to_e_NN(edge_combi)
            hij = message

            # edge --> node aggregate the messages hi' = sum(mij')
            message = tf.math.unsorted_segment_mean(message,
                                              edge_indices[:, 0],
                                              num_segments=tf.shape(node_features)[0],
                                              )

            # Construct the message matrix: mij' = [hi, hij']
            message_combi = tf.concat((hi, message), 1)
            hi = e_to_n_NN(message_combi)


        # Edge classification:
        x = edge_classification(hij)
        x = layers.Dense(64, kernel_initializer=tf.keras.initializers.HeNormal())(x)
        x = tf.keras.layers.LeakyReLU()(x)
        x = tf.keras.layers.LeakyReLU()(x)
        x = layers.Dense(1,
                         kernel_initializer=tf.keras.initializers.HeNormal(),
                         # kernel_regularizer=tf.keras.regularizers.L1(0.01),
                         # activity_regularizer=tf.keras.regularizers.L2(0.01),
                         activation="sigmoid")(x)


        Inputs=[node_features, edge_features, edge_indices]
        model = tf.keras.Model(inputs=Inputs, outputs=[x], name='mpnn')
        return model


